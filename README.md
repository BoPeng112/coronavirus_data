# Data and scripts for coronavirus project. 

# Please update this README when adding any new files. 

## data/
- `combined_binarized_sars.csv` is our main training data, with 1 for the 400 positives and 0 for the 300K negatives. 
- the test sets we want to predict on for now are:
  - `broad_repurposing_library.csv`, `external_library.csv` (the 866 molecules that Robert Malone sent us)
  - `expanded_external_library.csv` (the ~2500 molecules that Robert Malone sent us afterward, which don't seem to be a superset of the previous).
- `corona_literature.csv` and `corona_literature_idex.csv` contain FDA-approved drugs that have been studied in the (generic) coronavirus literature. These are not guaranteed to be effective against any targets; they simply appear in the literature. 
  - `corona_literature.csv` was generated through direct name matches at https://www.cureffi.org/wp-content/uploads/2013/10/drugs.txt
  - `corona_literature_idex.csv` was generated through the PubChem idex service and may contain multiple SMILES for generic drug names. 
  - `evaluation_set_v1.csv` is the combination of the broad repurposing library with Robert Malone's 60 reference actives, with those present in the training data removed. Reference actives are labeled as 1 while the broad library is labeled as 0. 
  - `individual_AID_test_sets` contains the test set corresponding to scaffold split 0 (see splits/ below) for each of the individual AID datasets.

# 317_combined_dataset_preds/ 
The most recent model predictions on each of the 3 test sets using the model trained on the combined 3 AID datasets. Predictions using only a single model with no hyperparameter opt or ensembling at the moment. For reference, benchmarking this model on scaffold split (5 folds) gets 0.7183 +/- 0.0095 AUC. 

# 316_AID1706only_preds/ 
The most recent model predictions on each of the 3 test sets using the model trained on only the AID1706 dataset. Predictions using only a single model with no hyperparameter opt or ensembling at the moment. For reference, benchmarking this model on scaffold split (5 folds) gets 0.7183 +/- 0.0095 AUC. If we decide that the AID485353 and AID652038 datasets aren't needed, we should go with these predictions. (This model got .963 AUC on evaluation_set_v1.csv, compared to .893 for the combined-data model.)

# conversions/
Files for converting between smiles/cid/name. Obtained from https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi

# similarity_computations/ 
The nearest neighbor computations from each test set to the training set. 

# scripts/ 
Various processing scripts for reuse/reproducibility.

# plots/ and statistics/ 
tsne plots of data distributions from different sets and some numerical stats about the data. 

# splits/
Cross-validation splits for the combined_binarized_sars.csv file. These are generated by scripts/create_crossval_splits.py in chemprop: https://github.com/chemprop/chemprop/blob/master/scripts/create_crossval_splits.py. There are 5 splits for each of random and scaffold, generated by making 5 folds and then picking 1 test fold and 1 val fold for each split. These are splits for model benchmarking purposes. When training a model for prediction of compounds to test in the lab, you should make sure to use the full data and not withhold extra data for testing. 

# raw_data/
Original raw data files and format conversions. 

# old/
Older versions of files from when we only used AID1706 and not the rest of the data. 
