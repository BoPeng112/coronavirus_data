# Data and scripts for coronavirus project. 

## data/
- `binarized_sars.csv` is our main training data, with 1 for the 400 positives and 0 for the 300K negatives. 
- the test sets we want to predict on for now are:
  - `broad_repurposing_library.csv`, `xternal_library.csv` (the 866 molecules that Robert Malone sent us)
  - `expanded_external_library.csv` (the ~2500 molecules that Robert Malone sent us afterward, which don't seem to be a superset of the previous).
- `corona_literature.csv` and `corona_literature_idex.csv` contain FDA-approved drugs that have been studied in the (generic) coronavirus literature. These are not guaranteed to be effective against any targets; they simply appear in the literature. 
  - `corona_literature.csv` was generated through direct name matches at https://www.cureffi.org/wp-content/uploads/2013/10/drugs.txt
  - `corona_literature_idex.csv` was generated through the PubChem idex service and may contain multiple SMILES for generic drug names. 

# raw_data/
Original raw data files and format conversions. 

# splits/
Cross-validation splits for the binarized_sars.csv file. These are generated by scripts/create_crossval_splits.py in chemprop: https://github.com/chemprop/chemprop/blob/master/scripts/create_crossval_splits.py. There are 5 splits for each of random and scaffold, generated by making 5 folds and then picking 1 test fold and 1 val fold for each split. These are splits for model benchmarking purposes. When training a model for prediction of compounds to test in the lab, you should make sure to use the full data and not withhold extra data for testing. 

# data conversions
For converting between data representations: https://pubchem.ncbi.nlm.nih.gov/idexchange/idexchange.cgi
